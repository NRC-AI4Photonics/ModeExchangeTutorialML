{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6216ed86",
   "metadata": {},
   "source": [
    "The notebook supports the tutorial publication ... The code includes the setup for running Ansys Lumerical simulations through the python API, executing a multiobjective optimization, as well as executing adjoint optimizations. Those can be used independently or in order to generate the data that is used to train neural network models.\n",
    "\n",
    "It has been tested with Python version =  3.9.20 and Ansys Lumerical v 2.4.1.\n",
    "\n",
    "@author: Grinbergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069810e9",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "new testing"
   },
   "outputs": [],
   "source": [
    "### Setup the environment \n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('C:\\\\Program Files\\\\Lumerical\\\\v241\\\\api\\\\python')  # pointer to the Python API folder of your Ansys Lumerical installation\n",
    "\n",
    "import numpy as np\n",
    "from lumopt.utilities.wavelengths import Wavelengths\n",
    "from lumopt.geometries.polygon import FunctionDefinedPolygon\n",
    "from lumopt.utilities.simulation import Simulation\n",
    "from lumopt.figures_of_merit.modematch import ModeMatch\n",
    "from lumopt.optimizers.generic_optimizers import ScipyOptimizers\n",
    "from lumopt.optimization import Optimization, SuperOptimization\n",
    "from lumopt.utilities.load_lumerical_scripts import load_from_lsf\n",
    "\n",
    "\n",
    "prj_dir = os.getcwd()\n",
    "n_params = 10 # number of parameters that define the shape\n",
    "param_bounds = [(0.1e-6, 2.2e-6)] * n_params # min and max values for each parameter\n",
    "Mode_names = ['TE0','TE1','TE2'] # appear as part of the mode expansion monitors in lsf file - \"mode_expansion_XXX\"\n",
    "\n",
    "total_len = 6e-6 # device length\n",
    "input_wg_width = 0.5e-6 # should be the same as the lsf file\n",
    "output_wg_width = 1e-6 # should be the same as the lsf file\n",
    "\n",
    "# geometry function\n",
    "# params represents [params_top, params_bottom]\n",
    "def mode_exchanger_geom(params):\n",
    "\n",
    "    # num of parameters must be even\n",
    "    assert (len(params)/2).is_integer()\n",
    "\n",
    "    Nx = int(len(params)/2)\n",
    "    dx = total_len / (Nx+1)\n",
    "\n",
    "    points_x = np.concatenate(\n",
    "        ([-total_len / 2], np.linspace(-total_len / 2 + dx, total_len / 2 - dx, Nx), [total_len / 2]))\n",
    "    points_y_top = np.concatenate(([input_wg_width/2], params[:Nx], [output_wg_width/2]))\n",
    "    points_y_bottom = np.concatenate(([input_wg_width/2], params[Nx:], [output_wg_width/2]))\n",
    "\n",
    "    px = np.linspace(points_x[0], points_x[-1], 100)\n",
    "    py_top = np.interp(px, points_x, points_y_top)\n",
    "    py_bottom = np.interp(px, points_x, points_y_bottom)\n",
    "    py_top[0] = points_y_top[0]\n",
    "    py_top[-1] = points_y_top[-1]\n",
    "    py_bottom[0] = points_y_bottom[0]\n",
    "    py_bottom[-1] = points_y_bottom[-1]\n",
    "\n",
    "    # new linear interpolation with filtering\n",
    "    # add 10 extra points per side to ensure smooth boundaries\n",
    "    # remember that points_x[0] is negative\n",
    "    px_long = np.concatenate((np.array([-10, -9, -8, -7, -6, -5, -4, -3, -2, -1]) * dx + points_x[0], px,\n",
    "                              np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) * dx + points_x[-1]))\n",
    "    py_long_top = np.concatenate((np.ones((10,)) * points_y_top[0], py_top, np.ones((10,)) * points_y_top[-1]))\n",
    "    py_long_bottom = np.concatenate((np.ones((10,)) * points_y_bottom[0], py_bottom, np.ones((10,)) * points_y_bottom[-1]))\n",
    "    \n",
    "    filt = np.exp(-np.power(px_long, 2.) / (2 * np.power(0.5e-7, 2.))) # gaussian smoothing \n",
    "    filtered_py_top = np.convolve(py_long_top, filt, mode='same')\n",
    "    filtered_py_bottom = np.convolve(py_long_bottom, filt, mode='same')\n",
    "    filtered_py_top = filtered_py_top / np.mean(filtered_py_top) * np.mean(py_long_top)\n",
    "    filtered_py_bottom = filtered_py_bottom / np.mean(filtered_py_bottom) * np.mean(py_long_bottom)\n",
    "    filtered_py_top = filtered_py_top[10:-10]\n",
    "    filtered_py_bottom = filtered_py_bottom[10:-10]\n",
    "    \n",
    "    # filtered_py[0] = py[0]\n",
    "    # filtered_py[-1] = py[-1]\n",
    "    py_top = filtered_py_top  # py #filtered_py\n",
    "    py_bottom = filtered_py_bottom  # py #filtered_py\n",
    "\n",
    "    polygon_points_up = [(x, y) for x, y in zip(px, py_top)]\n",
    "    polygon_points_down = [(x, -y) for x, y in zip(px, py_bottom)]\n",
    "    polygon_points = np.array(polygon_points_up[::-1] + polygon_points_down)\n",
    "    return polygon_points\n",
    "\n",
    "global_sample_function = lambda: np.array([np.round(np.random.uniform(min_val, max_val),10) for min_val, max_val in param_bounds])\n",
    "init_params = global_sample_function().flatten()\n",
    "\n",
    "geometry = FunctionDefinedPolygon(func=mode_exchanger_geom,\n",
    "                                  initial_params=init_params,\n",
    "                                  bounds=param_bounds,\n",
    "                                  z=0,\n",
    "                                  depth=220e-9,\n",
    "                                  eps_out=1.44 ** 2,\n",
    "                                  eps_in=2.8 ** 2,\n",
    "                                  edge_precision=5,\n",
    "                                  dx=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7cc1c7",
   "metadata": {
    "title": "Simulation setup"
   },
   "outputs": [],
   "source": [
    "### Load Lumerical lsf file and add random geometry, then save to the fsp file that is later used to run simulations\n",
    "### This is also used for testing to make sure everything is smooth in defining the gemoetry\n",
    "sim = Simulation(prj_dir,\n",
    "                 False, False)\n",
    "sim.fdtd.switchtolayout()\n",
    "sim.fdtd.eval(f'mode_exchanger;')\n",
    "geometry.add_geo(sim, init_params, False)\n",
    "sim.save(f\"ModeExchanger.fsp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681b30a",
   "metadata": {
    "title": "Run a single simulation"
   },
   "outputs": [],
   "source": [
    "#### For testing - simulate one structure and output the results\n",
    "\n",
    "# note that the output of LUMOPT produces values that have min-bound subtracted! You would need to add \"param_bounds[0][0]\"\n",
    "params = np.array([4.839e-07,7.772e-07,1.4823e-06,1.3544e-06,8.078e-07,5.083e-07,4.839e-07,7.772e-07,1.4823e-06,1.3544e-06]) \n",
    "\n",
    "sim = Simulation(prj_dir,\n",
    "                 False, False)\n",
    "sim.load(f\"ModeExchanger.fsp\")\n",
    "sim.fdtd.switchtolayout()\n",
    "\n",
    "# delete old shape if exists\n",
    "script=('selectpartial(\"polygon\");' +\n",
    "        'delete;')\n",
    "sim.fdtd.eval(script)\n",
    "\n",
    "# add new geometry\n",
    "geometry.add_geo(sim, params, False)\n",
    "sim.fdtd.run()\n",
    "\n",
    "FOMs = []\n",
    "for TE_name in Mode_names:\n",
    "        exp_TE = sim.fdtd.getresult(\"mode_expansion_\" + TE_name, \"expansion for input\")\n",
    "        data_TE = np.mean(exp_TE[\"T_net\"])\n",
    "\n",
    "        # round to 10^-4 resolution\n",
    "        data_TE = np.round(data_TE,4)\n",
    "        FOMs.append(data_TE)    \n",
    "\n",
    "output = str([f'{Mode_names[i]} = {FOMs[i]} ' for i in range(len(Mode_names))])\n",
    "output = output.translate(str.maketrans('', '', \"'[]\"))\n",
    "print(output)\n",
    "\n",
    "sim.fdtd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18181808",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup for pyMOO\n",
    "\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.core.problem import Problem\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "seed = 2 # random seed for reproducibility, also allows to restart the optimization from the last point it stopped (if lumopt failed)\n",
    "n_Population = 50\n",
    "n_Generations = 10\n",
    "parallel = 4 # number of parallel simulations to run\n",
    "fsp_prefix = f'analysis'\n",
    "\n",
    "FOM_store = ['TE0','TE1','TE2'] # all FOMs to compute and store (we may want to store more data than what we optimize for)\n",
    "FOM_opt_id = [0,1,2] # indexes of FOMs that the optimizer will optimize from FOM_store\n",
    "\n",
    "csv_file = f'data_p{n_Population}_g{n_Generations}_s{seed}_FOM[{[FOM_store[i] for i in FOM_opt_id]}].csv' # output file\n",
    "\n",
    "# create the fsp files for parallel simulations if not exist yet\n",
    "source_path = os.path.join(prj_dir,f\"ModeExchanger.fsp\")\n",
    "for i in range(parallel):\n",
    "    if not os.path.exists(os.path.join(prj_dir,fsp_prefix + str(i) + '.fsp')):\n",
    "        try:\n",
    "            shutil.copy(source_path, os.path.join(prj_dir,fsp_prefix + str(i) + '.fsp'))\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred while copying the file:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e302c82",
   "metadata": {
    "title": "running pymoo"
   },
   "outputs": [],
   "source": [
    "### Run pyMOO\n",
    "\n",
    "def load_existing_results(file_path):\n",
    "    \"\"\"\n",
    "    Load already computed results from the CSV file.\n",
    "    Returns a dictionary with tuples of the input array as keys and result as values.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return {}\n",
    "\n",
    "    results = {}\n",
    "    with open(file_path, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        \n",
    "        for line_number, row in enumerate(reader, start=1):  # Start line numbers from 1\n",
    "            if line_number == 1: # skip the header\n",
    "                continue\n",
    "\n",
    "            # Convert row to array and result\n",
    "            input_array = tuple(map(float, row[:-len(FOM_store)]))  # All but the last three columns are the input\n",
    "            result = [float(row[n_params+i]) for i in range(len(FOM_store))]  # Last column is the result\n",
    "            results[input_array] = (result,line_number)\n",
    "    return results\n",
    "\n",
    "\n",
    "def check_for_duplicates(file_path):\n",
    "    \"\"\"\n",
    "    Check the CSV file for duplicate inputs .\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"CSV file does not exist.\")\n",
    "        return\n",
    "\n",
    "    unique_entries = {}\n",
    "    duplicates = False\n",
    "\n",
    "    with open(file_path, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header_skipped = False\n",
    "\n",
    "        for row in reader:\n",
    "            if not header_skipped:\n",
    "                header_skipped = True\n",
    "                continue\n",
    "\n",
    "            input_array = tuple(map(float, row[:-1]))\n",
    "            result = float(row[-1])\n",
    "            # Store only the first occurrence of each input\n",
    "            if input_array in unique_entries:\n",
    "                duplicates = True\n",
    "                print(\"Duplicate: \" + str(input_array))\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "# Problem definition for PyMOO\n",
    "class MyProblem(Problem):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(n_var=n_params, n_obj=len(FOM_opt_id), n_ieq_constr=0, \n",
    "                         xl=[bound[0] for bound in param_bounds], \n",
    "                         xu=[bound[1] for bound in param_bounds], \n",
    "                         **kwargs)\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "\n",
    "        id_nxt = 0 # simultion progress index\n",
    "        sim = Simulation(prj_dir, False, False)\n",
    "\n",
    "        FOMs = np.zeros((X.shape[0],len(FOM_opt_id)))\n",
    "\n",
    "        headers = [\"param_\" + str(i) for i in range(n_params)] + FOM_store\n",
    "        \n",
    "        # round X to the 10^-10 resolution\n",
    "        X = np.round(X,10)\n",
    "\n",
    "        # Check if the file exists and load the results\n",
    "        file_exists = os.path.exists(csv_file)\n",
    "        processed_results = load_existing_results(csv_file)\n",
    "\n",
    "        # save the rng state before calling sim functions (they alter the state for some reason!)\n",
    "        rng_state = np.random.get_state()\n",
    "\n",
    "        # one iteration of this loop executes up to *parallel* number of simulations\n",
    "        while id_nxt < X.shape[0]:\n",
    "\n",
    "            all_found = True # if all simulations in this iteration have already been precomputed\n",
    "            for i in range(id_nxt,min(X.shape[0],id_nxt+parallel)):\n",
    "                params = X[i,:]\n",
    "                \n",
    "                input_tuple = tuple(params)  # Convert array to tuple for comparison\n",
    "                if input_tuple not in processed_results:\n",
    "                    all_found = False\n",
    "\n",
    "            # load precomputed results instead of running Lumerical\n",
    "            if all_found:\n",
    "                for i in range(id_nxt,min(X.shape[0],id_nxt+parallel)):\n",
    "                    params = X[i,:]\n",
    "                    input_tuple = tuple(params)  # Convert array to tuple for comparison\n",
    "                    res, lineID = processed_results[input_tuple]\n",
    "                    print(f'line loaded: {lineID}')\n",
    "                    FOMs[i,:] = np.array([res[j] for j in FOM_opt_id])\n",
    "\n",
    "            # run missing simulations\n",
    "            else:\n",
    "                # prepare the sim files\n",
    "                for i in range(id_nxt,min(X.shape[0],id_nxt+parallel)):\n",
    "                    params = X[i,:]\n",
    "\n",
    "                    sim.load(fsp_prefix + str(i % parallel) + \".fsp\")\n",
    "                    sim.fdtd.switchtolayout()\n",
    "                    script=('selectpartial(\"polygon\");' +\n",
    "                            'delete;')\n",
    "                    sim.fdtd.eval(script)\n",
    "                    geometry.add_geo(sim, params, False)\n",
    "                    sim.save(fsp_prefix + str(i % parallel) + \".fsp\")\n",
    "\n",
    "\n",
    "                fsp_files = [fsp_prefix + str(n) + \".fsp\" for n in range(parallel)]\n",
    "                for fsp_file in fsp_files:\n",
    "                    sim.fdtd.addjob(fsp_file)\n",
    "        \n",
    "                # Run the job queue\n",
    "                sim.fdtd.runjobs()\n",
    "\n",
    "                # read the output from simulations\n",
    "                for i in range(id_nxt,min(X.shape[0],id_nxt+parallel)):\n",
    "                    params = X[i,:]\n",
    "                    \n",
    "                    # Read the simulation results only if they are not already stored\n",
    "                    input_tuple = tuple(params)  # Convert array to tuple for comparison\n",
    "                    if input_tuple in processed_results:\n",
    "                        input_tuple = tuple(params)  # Convert array to tuple for comparison\n",
    "                        res, lineID = processed_results[input_tuple]\n",
    "                        print(f'line loaded: {lineID}')\n",
    "                        FOMs[i,:] = np.array([res[j] for j in FOM_opt_id])\n",
    "                        continue\n",
    "\n",
    "                    sim.load(fsp_prefix + str(i % parallel) + \".fsp\")\n",
    "\n",
    "                    FOMs_all = []\n",
    "                    for TE_name in FOM_store:\n",
    "                        exp_TE = sim.fdtd.getresult(\"mode_expansion_\" + TE_name, \"expansion for input\")\n",
    "                        data_TE = np.mean(exp_TE[\"T_net\"])\n",
    "\n",
    "                        # round to 10^-4 resolution\n",
    "                        data_TE = np.round(data_TE,4)\n",
    "                        FOMs_all.append(data_TE)    \n",
    "\n",
    "                    FOMs[i,:] = np.array([FOMs_all[j] for j in FOM_opt_id])\n",
    "\n",
    "                    with open(csv_file, mode='a', newline='') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        # Write headers only if the file doesn't exist\n",
    "                        if not file_exists:\n",
    "                            writer.writerow(headers)\n",
    "                            file_exists = True\n",
    "                        \n",
    "                        new_row = X[i,:].tolist() + FOMs_all\n",
    "                        writer.writerow(new_row)\n",
    "\n",
    "            id_nxt = id_nxt + parallel\n",
    "\n",
    "        # Dtore the function values and return them to the optimizer. The negative sign is due to minimization.\n",
    "        out[\"F\"] = -FOMs\n",
    "\n",
    "        # reset the random number generator state back to before Lumerical was called\n",
    "        np.random.set_state(rng_state)\n",
    "\n",
    "problem = MyProblem()\n",
    "\n",
    "\n",
    "algorithm = NSGA2(pop_size=n_Population)\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               ('n_gen', n_Generations),\n",
    "               seed=seed,\n",
    "               verbose=True)\n",
    "\n",
    "# dboule check there are no duplicates in the stored results (just for testing)\n",
    "print(\"Duplicates? \" + str(check_for_duplicates(csv_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the output of the pareto frontier independently\n",
    "\n",
    "frontier_file = f'frontier_p{n_Population}_g{n_Generations}_s{seed}_FOM[{[FOM_store[i] for i in FOM_opt_id]}].csv'\n",
    "header = str(['param_' + str(i) for i in range(n_params)] + [FOM_store[i] for i in FOM_opt_id]).replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "\n",
    "np.savetxt(\n",
    "    frontier_file,\n",
    "    np.hstack((res.X,np.abs(res.F))),\n",
    "    delimiter=',',\n",
    "    fmt=('%.4e',)*n_params + ('%.4f',)*len(FOM_opt_id),  # Different formats for each column\n",
    "    header=header,\n",
    "    comments=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1043f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adjoint with multiple objectives - function definition\n",
    "\n",
    "# input: target_eff - target power distribution between modes, such as [0.1, 0.5, 0.4]\n",
    "#        init_params - starting point for Lumopt\n",
    "# \n",
    "# returns a tuple of : initial FOM, final FOM, final geometry parameters, # of iterations\n",
    "\n",
    "import os \n",
    "LUMOPT_MAX_ITER = 5\n",
    "\n",
    "def lumopt_mode_exchanger(target_eff,init_params):\n",
    "\n",
    "    os.chdir(prj_dir)\n",
    "    # Initialize FunctionDefinedPolygon class\n",
    "    polygon = FunctionDefinedPolygon(func = mode_exchanger_geom,\n",
    "                                    initial_params = init_params,\n",
    "                                    # initial_params = [3.40E-07, 4.02E-07, 9.66E-07, 4.88E-07, 8.23E-07, 6.92E-07, 7.60E-07, 7.18E-07, 6.82E-07, 7.01E-07],\n",
    "                                    bounds = param_bounds,\n",
    "                                    z = 0,\n",
    "                                    depth = 220e-9,\n",
    "                                    eps_out = 1.44**2,\n",
    "                                    eps_in = 2.8**2,\n",
    "                                    edge_precision = 5,\n",
    "                                    dx = 1e-9)\n",
    "\n",
    "\n",
    "    ######## FIGURE OF MERIT ########\n",
    "    fom1 = ModeMatch(monitor_name = 'fom_1',\n",
    "                    mode_number = 2,\n",
    "                    direction = 'Forward',\n",
    "                    target_T_fwd = lambda wl: np.ones(wl.size) * target_eff[0],\n",
    "                    norm_p = 1)\n",
    "\n",
    "    fom2 = ModeMatch(monitor_name = 'fom_2',\n",
    "                    mode_number = 6,\n",
    "                    direction = 'Forward',\n",
    "                    target_T_fwd = lambda wl: np.ones(wl.size) * target_eff[1],\n",
    "                    norm_p = 1)\n",
    "    \n",
    "    fom3 = ModeMatch(monitor_name = 'fom_3',\n",
    "                    mode_number = 10,\n",
    "                    direction = 'Forward',\n",
    "                    target_T_fwd = lambda wl: np.ones(wl.size) * target_eff[2],\n",
    "                    norm_p = 1)\n",
    "\n",
    "    ######## OPTIMIZATION ALGORITHM ########\n",
    "    optimizer = ScipyOptimizers(max_iter = LUMOPT_MAX_ITER,\n",
    "                                method = 'L-BFGS-B',\n",
    "                                #scaling_factor = scaling_factor,\n",
    "                                pgtol = 1.0e-5,\n",
    "                                ftol = 1.0e-5,\n",
    "                                #target_fom = 0.0,\n",
    "                                scale_initial_gradient_to = 0.0)\n",
    "\n",
    "    wavelengths = Wavelengths(start=1530e-9, stop=1570e-9, points=11)\n",
    "    script = load_from_lsf(f'mode_exchanger_lumopt.lsf')\n",
    "\n",
    "    opt1 = Optimization(base_script=script, wavelengths=wavelengths, fom=fom1, geometry=polygon, optimizer=optimizer,\n",
    "                        use_deps=True, hide_fdtd_cad=False, plot_history=False, store_all_simulations=False,\n",
    "                        save_global_index=False)\n",
    "    opt2 = Optimization(base_script=script, wavelengths=wavelengths, fom=fom2, geometry=polygon, optimizer=optimizer,\n",
    "                        use_deps=True, hide_fdtd_cad=False, plot_history=False, store_all_simulations=False,\n",
    "                        save_global_index=False)\n",
    "    opt3 = Optimization(base_script=script, wavelengths=wavelengths, fom=fom3, geometry=polygon, optimizer=optimizer,\n",
    "                        use_deps=True, hide_fdtd_cad=False, plot_history=False, store_all_simulations=False,\n",
    "                        save_global_index=False)\n",
    "\n",
    "    ######## PUT EVERYTHING TOGETHER AND RUN ########\n",
    "    opt = SuperOptimization((opt1, opt2, opt3))\n",
    "\n",
    "    ######## RUN THE OPTIMIZATION ########\n",
    "    results = opt.run(working_dir=os.path.join(prj_dir,'optimizations','opts'))\n",
    "    \n",
    "    # close all sessions\n",
    "    for opt_i in opt.optimizations:\n",
    "        opt_i.sim.fdtd.close()\n",
    "\n",
    "    return((np.abs(opt.fom_hist[0]),) + results + (len(opt.fom_hist),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7eb3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing adjoint\n",
    "target_eff = [0.3,0.3,0.4]\n",
    "init_params = global_sample_function().flatten()\n",
    "fom_start, fom_end, params_out, iter = lumopt_mode_exchanger(target_eff,init_params)\n",
    "print(f'initial FOM = {fom_start}, final FOM = {fom_end}, # of iterations = {iter}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "3p9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
